{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lucku\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucku\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, joblib, click, nltk\n",
      "Successfully installed click-8.1.8 joblib-1.4.2 nltk-3.9.1 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lucku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crypto market steeply declined since january 20th donald trump assumed office us president', 'recent selloffs seen bitcoin ethereum dip sharply investors liquidate crypto holdings', 'analysts believe selloff could result macroeconomic uncertainty us following trumpâ€™s proposed economic policies regarding tariffs taxes', 'two crypto assets decline ethereum bitcoin traders shifted focus new defi project massive long term potential', 'bitcoin price prediction bitcoinâ€™s price recently fell fourmonth low dipping 77000 recovering slightly 80000']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Download necessary resources (run only once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_sentences(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Sentence Tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Process each sentence\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Remove punctuation\n",
    "        sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        # Tokenize sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "\n",
    "        # Remove stopwords\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        # Reconstruct the sentence\n",
    "        cleaned_sentence = \" \".join(filtered_words)\n",
    "\n",
    "        if cleaned_sentence:  # Ensure it's not empty\n",
    "            cleaned_sentences.append(cleaned_sentence)\n",
    "\n",
    "    return cleaned_sentences\n",
    "\n",
    "# Read the extracted text from file\n",
    "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Apply preprocessing\n",
    "cleaned_sentences = preprocess_sentences(raw_text)\n",
    "\n",
    "# Print sample cleaned sentences\n",
    "print(cleaned_sentences[:5])  # Print first 5 processed sentences\n",
    "\n",
    "# Save cleaned sentences into a new file\n",
    "with open(\"cleaned_output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(cleaned_sentences))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
